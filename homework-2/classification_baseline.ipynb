{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "classification_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWGO2uFHpubx",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Classification task\n",
        "\n",
        "Hi! It's a classification task baseline notebook.\n",
        "It include a data reader, baseline model and submission generator.\n",
        "\n",
        "You should use GPU to train your model, so we recommend using [Kaggle Notebooks](https://www.kaggle.com/docs/notebooks).\n",
        "To get maximum score of the task, your model should have accuracy greater than `85%`.\n",
        "\n",
        "You can use everything, that suits into the rules in `README.md`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "uj8guJf_vbP2"
      },
      "source": [
        "!pip install catalyst optuna ttach torch-lr-finder\n",
        "!pip install --upgrade wandb\n",
        "!pip install -U albumentations\n",
        "#!wandb login 03248ab38d989b0a18ea64ce321cb8ab13a801e6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykwoX9iJ3Y2S"
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1xD8Qx33LeefTXe_KNzERM3TdA4r-UZkA&export=download\n",
        "!gdown https://drive.google.com/uc?id=1WWiuL8sXlMoBnpbkbqv3tDFgR1Rk_nPE&export=download\n",
        "!unzip train.zip -d train\n",
        "!unzip test.zip -d test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtKdA2dqGEk"
      },
      "source": [
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "import torchvision\n",
        "\n",
        "import catalyst\n",
        "from catalyst import dl\n",
        "from catalyst.utils import metrics, set_global_seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v949FHgsQy62"
      },
      "source": [
        "set_global_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzZ_ShWyJXrJ"
      },
      "source": [
        "### Make extra images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOUsJBqd-Pgf"
      },
      "source": [
        "#This function is not necessary, but can boost perfomance\n",
        "def make_extra_images(image_roots):\n",
        "    \"\"\"Function will make extra pictures with horizontal and vertical reflection.\n",
        "    \"\"\"\n",
        "\n",
        "    print('Extra pictures generation started...', end='')\n",
        "    prefix_names = ['_090', '_180', '_270']\n",
        "\n",
        "    for path in image_roots:\n",
        "        files = os.listdir(path)\n",
        "        files = list(filter(lambda x: x.endswith('.jpg') and not any([pr in x for pr in prefix_names]), files))\n",
        "\n",
        "        for i, file in enumerate(files):\n",
        "            img = cv2.imread(os.path.join(path,file))\n",
        "            # Make extra pictures: flip each of originals photo to 90, 180 and 270 degrees\n",
        "            for i, angle in enumerate([cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE]):\n",
        "                img = cv2.rotate(img, angle)\n",
        "                img_name = os.path.join(path, file[:file.find('.')] + prefix_names[i] + file[file.find('.'):])\n",
        "                if not os.path.exists(img_name):\n",
        "                    cv2.imwrite(img_name, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TU1ptVP_v5f",
        "outputId": "d8005ada-88b4-4d98-ba4a-76cdf0e624eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "make_extra_images(image_roots=['/content/train/c1d6f6c4',\n",
        "                               '/content/train/c1d6fa84',\n",
        "                               '/content/train/c1d6fc6e',\n",
        "                               '/content/train/c1d6fd90',\n",
        "                               '/content/train/c1d6fe94',\n",
        "                               '/content/train/c1d6ff98',\n",
        "                               '/content/train/c1d70092',\n",
        "                               '/content/train/c1d70196',\n",
        "                               '/content/train/c1d702ae',\n",
        "                               '/content/train/c1d70420'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extra pictures generation started..."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgU_DOniQR1p",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Dataset\n",
        "\n",
        "This code will help you to generate dataset. If your data have the following folder structure:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "    class_1/\n",
        "        *.ext\n",
        "        ...\n",
        "    class_2/\n",
        "        *.ext\n",
        "        ...\n",
        "    ...\n",
        "    class_N/\n",
        "        *.ext\n",
        "        ...\n",
        "```\n",
        "First of all `create_dataset` function goes through a given directory and creates a dictionary `Dict[class_name, List[image]]`.\n",
        "Then `create_dataframe` function creates typical `pandas.DataFrame` for further analysis.\n",
        "After than `prepare_dataset_labeling` creates a numerical label for each unique class name.\n",
        "Finally, to add a column with a numerical label value to the DataFrame, we can use `map_dataframe` function.\n",
        "\n",
        "Additionaly let's save the `class_names` for further usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Y0umM7buvbQC",
        "outputId": "c717ed5f-2044-4074-e607-f217f0c5c1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "from catalyst.utils import (\n",
        "    create_dataset, create_dataframe, get_dataset_labeling, map_dataframe\n",
        ")\n",
        "\n",
        "dataset = create_dataset(dirs=f\"train/*\", extension=\"*.jpg\")\n",
        "df = create_dataframe(dataset, columns=[\"class\", \"filepath\"])\n",
        "\n",
        "tag_to_label = get_dataset_labeling(df, \"class\")\n",
        "class_names = [\n",
        "    name for name, id_ in sorted(tag_to_label.items(), key=lambda x: x[1])\n",
        "]\n",
        "\n",
        "df_with_labels = map_dataframe(\n",
        "    df, \n",
        "    tag_column=\"class\", \n",
        "    class_column=\"label\", \n",
        "    tag2class=tag_to_label, \n",
        "    verbose=False\n",
        ")\n",
        "df_with_labels.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>filepath</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c1d6f6c4</td>\n",
              "      <td>train/c1d6f6c4/bfeddcd4.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c1d6f6c4</td>\n",
              "      <td>train/c1d6f6c4/bff0a9a0.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c1d6f6c4</td>\n",
              "      <td>train/c1d6f6c4/bff1d1a4.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c1d6f6c4</td>\n",
              "      <td>train/c1d6f6c4/bff3363e.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c1d6f6c4</td>\n",
              "      <td>train/c1d6f6c4/bff4d7b4.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      class                     filepath  label\n",
              "0  c1d6f6c4  train/c1d6f6c4/bfeddcd4.jpg      0\n",
              "1  c1d6f6c4  train/c1d6f6c4/bff0a9a0.jpg      0\n",
              "2  c1d6f6c4  train/c1d6f6c4/bff1d1a4.jpg      0\n",
              "3  c1d6f6c4  train/c1d6f6c4/bff3363e.jpg      0\n",
              "4  c1d6f6c4  train/c1d6f6c4/bff4d7b4.jpg      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "06XGevdMvbQG"
      },
      "source": [
        "And you should split data in `train/valid/test` parts.\n",
        "There are only `train` and `valid` parts, so you must load test data as shows in a code cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEhBS2sqQZ1z"
      },
      "source": [
        "from catalyst.utils import split_dataframe_train_test\n",
        "\n",
        "train_data, valid_data = split_dataframe_train_test(\n",
        "    df_with_labels, test_size=0.2, random_state=42, stratify = df_with_labels['label'].values\n",
        ")\n",
        "train_data, valid_data = (\n",
        "    train_data.to_dict(\"records\"),\n",
        "    valid_data.to_dict(\"records\"),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1upnlv4RV2m"
      },
      "source": [
        "from catalyst.data.cv.reader import ImageReader\n",
        "from catalyst.dl import utils\n",
        "from catalyst.data import ScalarReader, ReaderCompose\n",
        "\n",
        "num_classes = len(tag_to_label)\n",
        "\n",
        "open_fn = ReaderCompose(\n",
        "    [\n",
        "        ImageReader(\n",
        "            input_key=\"filepath\", output_key=\"features\", rootpath=\"train/\"\n",
        "        ),\n",
        "        ScalarReader(\n",
        "            input_key=\"label\",\n",
        "            output_key=\"targets\",\n",
        "            default_value=-1,\n",
        "            dtype=np.int64,\n",
        "        ),\n",
        "        ScalarReader(\n",
        "            input_key=\"label\",\n",
        "            output_key=\"targets_one_hot\",\n",
        "            default_value=-1,\n",
        "            dtype=np.int64,\n",
        "            one_hot_classes=num_classes,\n",
        "        ),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "7yRA8oLSvbQN"
      },
      "source": [
        "## Augmentation\n",
        "\n",
        "In a baseline, we don't have augmentation transformations in the baseline.\n",
        "You can add them, if you expect that it will increase model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioYI0Kj_wVU1"
      },
      "source": [
        "#AutoAugment - Learning Augmentation Policies from Data\n",
        "#superior method for image augmentations\n",
        "!git clone https://github.com/DeepVoltaire/AutoAugment.git\n",
        "!mv /content/AutoAugment/autoaugment.py /content/autoaugment.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zYtvpiIBJFz"
      },
      "source": [
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensor\n",
        "from autoaugment import ImageNetPolicy\n",
        "from PIL import Image\n",
        "from torchvision import transforms as trns\n",
        "\n",
        "\n",
        "transform_to_tensor = albu.Compose(\n",
        "    [   \n",
        "     albu.Resize(224, 224),\n",
        "     albu.Normalize(),\n",
        "     ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "transforms_imagenet = lambda image : {'image': trns.Compose([\n",
        "                                       trns.ToPILImage(),\n",
        "                                       trns.RandomResizedCrop(224),\n",
        "                                       ImageNetPolicy(),\n",
        "                                       trns.ToTensor(),\n",
        "                                       trns.Normalize([0.485, 0.456, 0.406],\n",
        "                                                      [0.229, 0.224, 0.225])])(image)}\n",
        "\n",
        "transforms_grid_mask = albu.Compose(\n",
        "    [\n",
        "     albu.Resize(224, 224),\n",
        "     albu.GridDropout(0.4, p = 1),\n",
        "     albu.Normalize(),\n",
        "     ToTensor()\n",
        "    ]\n",
        ")\n",
        "\n",
        "own_transforms = albu.Compose(\n",
        "    [albu.OneOf(\n",
        "         [\n",
        "          albu.RandomRotate90(p = 1),\n",
        "          albu.HorizontalFlip(p = 1),\n",
        "         ],\n",
        "     p = 1),\n",
        "     albu.Resize(224, 224),\n",
        "     albu.Normalize(),\n",
        "     ToTensor()\n",
        "    ]\n",
        ")\n",
        "transformations = {'autoaugment': transforms_imagenet,\n",
        "                   'to_tensor': transform_to_tensor,\n",
        "                   'grid_mask': transforms_grid_mask,\n",
        "                   'own_transforms': own_transforms}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ1hwc8NRVxB"
      },
      "source": [
        "from catalyst.data import Augmentor\n",
        "\n",
        "data_transforms = lambda transform: Augmentor(\n",
        "    dict_key=\"features\", augment_fn=lambda x: transformations[transform](image=x)[\"image\"]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-4HVfMiRuxM",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Don't forget creating test loader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Sd5aOQ69vbQT"
      },
      "source": [
        "batch_size = 16\n",
        "num_workers = 4\n",
        "\n",
        "train_loader = lambda augment: utils.get_loader(\n",
        "    train_data,\n",
        "    open_fn=open_fn,\n",
        "    dict_transform=data_transforms(augment),\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=True,\n",
        "    sampler=None,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "valid_loader = utils.get_loader(\n",
        "    valid_data,\n",
        "    open_fn=open_fn,\n",
        "    dict_transform=data_transforms('to_tensor'),\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    shuffle=False, \n",
        "    sampler=None,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "loaders = lambda augment: {\n",
        "    \"train\": train_loader(augment),\n",
        "    \"valid\": valid_loader\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6P8ZzbjyvbQV"
      },
      "source": [
        "## Model\n",
        "\n",
        "For the baseline, we will use a ResNet model.\n",
        "We already have examined in the seminar.\n",
        "Enhance the model, use any* instruments or module as you like.\n",
        "\n",
        "*(Don't forget about the rules!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vnP7SIzsdyk"
      },
      "source": [
        "from catalyst.contrib.nn.schedulers.onecycle import OneCycleLRWithWarmup\n",
        "from torch.optim.lr_scheduler import CyclicLR, ReduceLROnPlateau\n",
        "from catalyst.contrib.nn.optimizers.lookahead import Lookahead\n",
        "from catalyst.contrib.nn.optimizers.radam import RAdam\n",
        "from torch.nn import ReLU, PReLU, GELU, LeakyReLU\n",
        "from catalyst.dl.callbacks import WandbLogger\n",
        "from catalyst.core.callback import Callback\n",
        "from collections import OrderedDict\n",
        "from torch.optim import AdamW, SGD\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmekLNhvA02h"
      },
      "source": [
        "class DenseLayer(nn.Module):\n",
        "    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.BatchNorm2d(num_input_features)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(num_input_features, bn_size *\n",
        "                                           growth_rate, kernel_size=1, stride=1,\n",
        "                                           bias=False)\n",
        "        self.norm2 = nn.BatchNorm2d(bn_size * growth_rate)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
        "                                           kernel_size=3, stride=1, padding=1,\n",
        "                                           bias=False)\n",
        "        self.drop_rate = float(drop_rate)\n",
        "\n",
        "    def bn_function(self, inputs):\n",
        "        concated_features = torch.cat(inputs, 1)\n",
        "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))\n",
        "        return bottleneck_output\n",
        "\n",
        "    def forward(self, input):\n",
        "        if isinstance(input, Tensor):\n",
        "            prev_features = [input]\n",
        "        else:\n",
        "            prev_features = input\n",
        "\n",
        "        bottleneck_output = self.bn_function(prev_features)\n",
        "        new_features = self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
        "        if self.drop_rate > 0:\n",
        "            new_features = F.dropout(new_features, p=self.drop_rate,\n",
        "                                     training=self.training)\n",
        "        return new_features\n",
        "\n",
        "\n",
        "class DenseBlock(nn.ModuleDict):\n",
        "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n",
        "        super().__init__()\n",
        "        for i in range(num_layers):\n",
        "            layer = DenseLayer(\n",
        "                num_input_features + i * growth_rate,\n",
        "                growth_rate=growth_rate,\n",
        "                bn_size=bn_size,\n",
        "                drop_rate=drop_rate\n",
        "            )\n",
        "            self.add_module('denselayer%d' % (i + 1), layer)\n",
        "\n",
        "    def forward(self, init_features):\n",
        "        features = [init_features]\n",
        "        for name, layer in self.items():\n",
        "            new_features = layer(features)\n",
        "            features.append(new_features)\n",
        "        return torch.cat(features, 1)\n",
        "\n",
        "\n",
        "class Transition(nn.Sequential):\n",
        "    def __init__(self, num_input_features, num_output_features):\n",
        "        super().__init__()\n",
        "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
        "        self.add_module('relu', nn.ReLU(inplace=True))\n",
        "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
        "                                          kernel_size=1, stride=1, bias=False))\n",
        "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
        "                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=10):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n",
        "                                padding=3, bias=False)),\n",
        "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
        "            ('relu0', nn.ReLU(inplace=True)),\n",
        "            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n",
        "        ]))\n",
        "\n",
        "        num_features = num_init_features\n",
        "        for i, num_layers in enumerate(block_config):\n",
        "            block = DenseBlock(\n",
        "                num_layers=num_layers,\n",
        "                num_input_features=num_features,\n",
        "                bn_size=bn_size,\n",
        "                growth_rate=growth_rate,\n",
        "                drop_rate=drop_rate\n",
        "            )\n",
        "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
        "            num_features = num_features + num_layers * growth_rate\n",
        "            if i != len(block_config) - 1:\n",
        "                trans = Transition(num_input_features=num_features,\n",
        "                                    num_output_features=num_features // 2)\n",
        "                self.features.add_module('transition%d' % (i + 1), trans)\n",
        "                num_features = num_features // 2\n",
        "\n",
        "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
        "        self.classifier = nn.Linear(num_features, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.features(x)\n",
        "        out = F.relu(features, inplace=True)\n",
        "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
        "        out = torch.flatten(out, 1)\n",
        "        out = self.classifier(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B26FN-CLq4cF",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "# Create Runner and train your model!\n",
        "\n",
        "class Runner(dl.Runner):\n",
        "    def predict_batch(self, batch):\n",
        "        return self.model(batch[0].to(self.device))\n",
        "\n",
        "    def _handle_batch(self, batch):\n",
        "        y_pred = self.model(batch[\"features\"])\n",
        "\n",
        "        self.input = batch\n",
        "        self.output = {\"logits\": y_pred}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-ytyqUP8OE2"
      },
      "source": [
        "from torch_lr_finder import LRFinder, TrainDataLoaderIter\n",
        "\n",
        "\n",
        "class TrainLoader(TrainDataLoaderIter):\n",
        "    def __init__(self, data_loader, auto_reset=True):\n",
        "        super().__init__(data_loader)\n",
        "\n",
        "    def inputs_labels_from_batch(self, batch_data):\n",
        "        inputs, labels, *_ = batch_data.values()\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "def find_lr(model, criterion, optimizer, augment):\n",
        "  loader = TrainLoader(loaders(augment)['train'])\n",
        "  if optimizer == 'sgd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), 0.01)\n",
        "  elif optimizer == 'adamW':\n",
        "    optimizer = AdamW(model.parameters())\n",
        "  elif optimizer == 'Radam':\n",
        "    optimizer = RAdam(model.parameters())\n",
        "  elif optimizer == 'adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "  elif optimizer == 'lookahead':\n",
        "    optimizer = Lookahead(AdamW(model.parameters()))\n",
        "\n",
        "  lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "  lr_finder.range_test(loader, end_lr=1, num_iter=100)\n",
        "\n",
        "  losses = np.array(lr_finder.history['loss'])\n",
        "  lrs = lr_finder.history['lr']\n",
        "  lr_finder.plot()\n",
        "  lr_finder.reset()\n",
        "  #find 3 lrs: optimal and lrs for cycliclr scheduler\n",
        "  max_lr = lrs[losses.argmin()]\n",
        "  min_lr = lrs[losses[:losses.argmin()].argmax()]\n",
        "  optimal = lrs[np.gradient(losses).argmin()]\n",
        "  return optimal, min_lr, max_lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOfvcgRNrNWh"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import wandb\n",
        "import optuna\n",
        "\n",
        "\n",
        "def model_train(activation, augment, optimizer_to_choose, scheduler_to_choose, lr, min_lr, max_lr):\n",
        "  model = DenseNet(48, (6, 12, 36, 24), 96)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  epoch = 60\n",
        "  optimizers = {'adamW': lambda x: AdamW(model.parameters(), lr = x),\n",
        "              'adam': lambda x: torch.optim.Adam(model.parameters(), lr = x),\n",
        "              'Radam': lambda x: RAdam(model.parameters(), lr = x),\n",
        "              'lookahead': lambda x: Lookahead(AdamW(model.parameters(), lr = x)),\n",
        "              'sgd': lambda x: torch.optim.SGD(model.parameters(), lr = x)}\n",
        "  optimizer = optimizers[optimizer_to_choose](lr)\n",
        "  schedulers = {'cyclic_lr': lambda x: CyclicLR(x, min_lr, max_lr, step_size_up=1),\n",
        "              'one_cycle': lambda x: OneCycleLRWithWarmup(x, num_steps = epoch, warmup_steps=2, lr_range=(max_lr, min_lr)),\n",
        "              'reduce_onplatue': lambda x: ReduceLROnPlateau(x, patience=2, factor = 0.5)}\n",
        "  scheduler = schedulers[scheduler_to_choose](optimizer)\n",
        "  config = {'optimizer': optimizer,\n",
        "          'batch_size': batch_size,\n",
        "          'scheduler': scheduler,\n",
        "          'epoch': epoch,\n",
        "          'augment': augment}\n",
        "\n",
        "  runner = Runner()\n",
        "  runner.train(\n",
        "      model=model,\n",
        "      optimizer=optimizer,\n",
        "      criterion=criterion,\n",
        "      scheduler = scheduler,\n",
        "      loaders=loaders(augment),\n",
        "      logdir=Path(\"logs\") / datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "      num_epochs=config['epoch'],\n",
        "      verbose=True,\n",
        "      load_best_on_end=True,\n",
        "      main_metric=\"loss\",\n",
        "      minimize_metric = True,\n",
        "      callbacks={\n",
        "          \"optimizer\": dl.OptimizerCallback(\n",
        "              metric_key=\"loss\", accumulation_steps=1, grad_clip_params=None,\n",
        "          ),\n",
        "          \"criterion\": dl.CriterionCallback(\n",
        "              input_key=\"targets\", output_key=\"logits\", prefix=\"loss\",\n",
        "          ),\n",
        "          \"accuracy\": dl.AccuracyCallback(num_classes=10),\n",
        "          \"scheduler\": dl.SchedulerCallback(),\n",
        "          'Wandb': WandbLogger(\n",
        "                          project=\"imagenette_classification\",\n",
        "                          name = f\"model_{optimizer_to_choose}_{scheduler_to_choose}_{augment}_{activation}\",\n",
        "                          config = config\n",
        "                          )\n",
        "      },\n",
        "  )\n",
        "  return runner, model\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-3)\n",
        "    activation = trial.suggest_categorical('activation', ['gelu'])\n",
        "    augment = trial.suggest_categorical('augment', ['autoaugment', 'to_tensor'])\n",
        "    min_lr = trial.suggest_loguniform(\"min_lr\", 1e-5, 1e-3)\n",
        "    max_lr = trial.suggest_loguniform(\"max_lr\", 1e-3, 1e-2)\n",
        "    optimizer = trial.suggest_categorical('optimizer', ['Radam'])\n",
        "    scheduler = trial.suggest_categorical('scheduler', ['one_cycle'])\n",
        "\n",
        "    runner, _ = model_train(trial, activation, augment, optimizer, scheduler, lr, min_lr, max_lr)\n",
        "    return runner.best_valid_metrics[runner.main_metric]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkYcjc6EDeXp"
      },
      "source": [
        "runner, model = model_train('prelu', 'autoaugment', 'Radam', 'reduce_onplatue', 1e-2, 1e-4, 1e-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrhxiMuJb6kQ"
      },
      "source": [
        "tqdm._instances.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbGKJtGCA__i"
      },
      "source": [
        "Test transforms are crucial in order to boost accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1f7StMdRV0S"
      },
      "source": [
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensor\n",
        "import ttach as tta\n",
        "\n",
        "\n",
        "transform_to_tensor = albu.Compose(\n",
        "    [\n",
        "        albu.Normalize(),\n",
        "        ToTensor(),\n",
        "    ]\n",
        ")\n",
        "transforms_list = { \n",
        "    'original': albu.Compose([\n",
        "        albu.Resize(224, 224),\n",
        "    ]),   \n",
        "    'crop_180': albu.Compose([\n",
        "        albu.CenterCrop(180, 180),\n",
        "        albu.Resize(224, 224),\n",
        "    ]),    \n",
        "    'crop_160': albu.Compose([\n",
        "        albu.CenterCrop(160, 160),\n",
        "        albu.Resize(224, 224),\n",
        "    ]),\n",
        "    'gray_200': albu.Compose([\n",
        "        albu.ToGray(p = 1),\n",
        "        albu.CenterCrop(200, 200),\n",
        "        albu.Resize(224, 224),\n",
        "    ]),\n",
        "    'r_crop_180_1': albu.Compose([\n",
        "        albu.RandomCrop(180, 180),\n",
        "        albu.Resize(224, 224),\n",
        "    ]),\n",
        "    'r_crop_180_2': albu.Compose([\n",
        "        albu.RandomCrop(180, 180),\n",
        "        albu.Resize(224, 224),\n",
        "    ]),\n",
        "    'r_crop_180_3': albu.Compose([\n",
        "        albu.ToGray(p = 1),\n",
        "        albu.RandomCrop(180, 180),\n",
        "        albu.Resize(224, 224),\n",
        "    ]),  \n",
        "    'rotate_90': albu.Compose([\n",
        "        albu.RandomRotate90(p = 1),\n",
        "        albu.Resize(224, 224)\n",
        "    ])    \n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "znjxsa7-vbQd"
      },
      "source": [
        "This code below will generate a submission.\n",
        "It reads images from `test` folder and gathers prediction from the trained model.\n",
        "Check your submission before uploading it into `Kaggle`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgNpIL-uS5KB",
        "outputId": "1eba2331-c437-45a6-beec-437a829f22b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "submission = {\"Id\": [], \"Category\": []}\n",
        "model.eval()\n",
        "\n",
        "for file in tqdm(Path(\"test\").iterdir(), total = len(os.listdir('test'))):\n",
        "    image = np.array(Image.open(file).convert('RGB'))\n",
        "    img = transforms_list['original'](image = image)['image']\n",
        "    input = transform_to_tensor(image = img)['image']\n",
        "    input = input.unsqueeze(0).cuda()\n",
        "    features = model(input)\n",
        "    probabilities = torch.softmax(features, -1)\n",
        "    \n",
        "    pred = probabilities.detach().cpu().numpy()\n",
        "    pred = np.argmax(pred)\n",
        "    submission[\"Id\"].append(file.name[:-4])\n",
        "    submission[\"Category\"].append(class_names[pred])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3925/3925 [02:41<00:00, 24.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8XOQD15S5Gh"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "pd.DataFrame(submission).to_csv(\"baseline.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF2oj8uFd2-J",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "source": [
        "pd.DataFrame(submission)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbTg7qNgvY5p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
